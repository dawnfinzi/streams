{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import nibabel as nibabel\n",
    "import pandas as pd\n",
    "import nibabel.freesurfer.mghformat as mgh\n",
    "import scipy.io\n",
    "import itertools \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../data/'\n",
    "local_data_dir = '../../../local_data/'\n",
    "\n",
    "subjid = ['01', '02', '03', '04', '05', '06', '07', '08']\n",
    "ROI_names = ['Unknown', 'Early', 'Midventral', 'Midlateral', 'Midparietal', 'Ventral', 'Lateral', 'Parietal']\n",
    "n_repeats = 3\n",
    "\n",
    "#threshold for voxels (based on split-half reliability)\n",
    "thresh = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get right hemi data and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ROI data\n",
    "rh_streams = []\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    mgh_file = mgh.load(data_dir+'nsddata/freesurfer/subj'+ sid +'/label/rh.streams.mgz')\n",
    "    rh_streams.append(mgh_file.get_fdata()[:,0,0])\n",
    "\n",
    "#get voxel level split-half reliability data\n",
    "reliability = []\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    \n",
    "    sh_dir = local_data_dir + 'freesurfer/subj' + sid + '/rh_split_half.mat'\n",
    "    sh = scipy.io.loadmat(sh_dir)\n",
    "    \n",
    "    reliability.append(sh['mean'])\n",
    "\n",
    "#get organized z-scored betas\n",
    "with open(local_data_dir + 'processed/rh_betas_by_repeat_by_ROI_zscore.data', 'rb') as filehandle:\n",
    "    # read the data as binary data stream\n",
    "    rh_betas_by_repeat_by_ROI = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace voxels with split-half reliability < thresh with NaNs and then trim those from data structure\n",
    "\n",
    "sh_by_ROI = [[[] for j in range(len(ROI_names)-1)] for i in range(len(subjid))]\n",
    "total_vox = np.zeros((len(subjid), len(ROI_names)-1))\n",
    "\n",
    "#organize\n",
    "for sidx, sid in enumerate(subjid):  \n",
    "    for roi_idx in range(len(ROI_names)-1):       \n",
    "        sh_by_ROI[sidx][roi_idx]=reliability[sidx][:,rh_streams[sidx] == roi_idx+1]\n",
    "        total_vox[sidx,roi_idx] = len(sh_by_ROI[sidx][roi_idx][0])\n",
    "\n",
    "#convert to nans\n",
    "for sidx, sid in enumerate(subjid):  \n",
    "    for roi_idx in range(len(ROI_names)-1): \n",
    "        for vox in range(len(sh_by_ROI[sidx][roi_idx][0])):\n",
    "            if sh_by_ROI[sidx][roi_idx][0][vox] < thresh:\n",
    "                rh_betas_by_repeat_by_ROI[sidx][roi_idx][0][:,vox]=np.nan\n",
    "                rh_betas_by_repeat_by_ROI[sidx][roi_idx][1][:,vox]=np.nan\n",
    "                rh_betas_by_repeat_by_ROI[sidx][roi_idx][2][:,vox]=np.nan    \n",
    "\n",
    "thresh_vox = np.zeros((len(subjid), len(ROI_names)-1))                \n",
    "#trim out nans\n",
    "for sidx, sid in enumerate(subjid):   \n",
    "    for roi_idx in range(len(ROI_names)-1): \n",
    "        for r in range(n_repeats):\n",
    "            temp = rh_betas_by_repeat_by_ROI[sidx][roi_idx][r]\n",
    "            trimmed = temp[:,~np.all(np.isnan(temp), axis=0)]\n",
    "\n",
    "            rh_betas_by_repeat_by_ROI[sidx][roi_idx][r] = trimmed\n",
    "        thresh_vox[sidx,roi_idx] = trimmed.shape[1]\n",
    "\n",
    "#gather number of remaining voxels for each ROI and subj\n",
    "vox = np.zeros((len(ROI_names)-1, len(subjid)))\n",
    "for roi_idx in range(len(ROI_names)-1):\n",
    "    vox[roi_idx,:] = [rh_betas_by_repeat_by_ROI[sidx][roi_idx][0].shape[1] for sidx, sid in enumerate(subjid)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RSMS for all the ROIs, repeats and subjects\n",
    "\n",
    "tril_flat_shape = int((rh_betas_by_repeat_by_ROI[0][0][0].shape[0]**2/2) - (rh_betas_by_repeat_by_ROI[0][0][0].shape[0]/2))\n",
    "rh_flat_rsm = np.zeros((len(subjid),len(ROI_names)-1, tril_flat_shape, n_repeats))\n",
    "rsm = np.zeros((len(subjid),len(ROI_names)-1,n_repeats,rh_betas_by_repeat_by_ROI[0][0][0].shape[0],rh_betas_by_repeat_by_ROI[0][0][0].shape[0]))\n",
    "\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    \n",
    "    for roi_idx in range(len(ROI_names)-1):\n",
    "        voxels = np.min(vox[roi_idx,:])\n",
    "        \n",
    "        for r in range(n_repeats):\n",
    "            rsm[sidx,roi_idx,r,:,:] = np.corrcoef(rh_betas_by_repeat_by_ROI[sidx][roi_idx][r])\n",
    "            lower = np.tril(rsm[sidx,roi_idx,r,:,:], -1).T.ravel() #only need lower triangle without diagonal\n",
    "            rh_flat_rsm[sidx, roi_idx, :,r] = lower[lower != 0] #flatten into vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get left hemi data and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ROI data\n",
    "lh_streams = []\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    mgh_file = mgh.load(data_dir+'nsddata/freesurfer/subj'+ sid +'/label/lh.streams.mgz')\n",
    "    lh_streams.append(mgh_file.get_fdata()[:,0,0])\n",
    "\n",
    "#get voxel level split-half reliability data\n",
    "reliability = []\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    \n",
    "    sh_dir = local_data_dir + 'freesurfer/subj' + sid + '/lh_split_half.mat'\n",
    "    sh = scipy.io.loadmat(sh_dir)\n",
    "    \n",
    "    reliability.append(sh['mean'])\n",
    "\n",
    "#get organized z-scored betas\n",
    "with open(local_data_dir + 'processed/lh_betas_by_repeat_by_ROI_zscore.data', 'rb') as filehandle:\n",
    "    # read the data as binary data stream\n",
    "    lh_betas_by_repeat_by_ROI = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace voxels with split-half reliability < thresh with NaNs and then trim those from data structure\n",
    "\n",
    "sh_by_ROI = [[[] for j in range(len(ROI_names)-1)] for i in range(len(subjid))]\n",
    "total_vox = np.zeros((len(subjid), len(ROI_names)-1))\n",
    "\n",
    "#organize\n",
    "for sidx, sid in enumerate(subjid):  \n",
    "    for roi_idx in range(len(ROI_names)-1):       \n",
    "        sh_by_ROI[sidx][roi_idx]=reliability[sidx][:,lh_streams[sidx] == roi_idx+1]\n",
    "        total_vox[sidx,roi_idx] = len(sh_by_ROI[sidx][roi_idx][0])\n",
    "\n",
    "#convert to nans\n",
    "for sidx, sid in enumerate(subjid):  \n",
    "    for roi_idx in range(len(ROI_names)-1): \n",
    "        for vox in range(len(sh_by_ROI[sidx][roi_idx][0])):\n",
    "            if sh_by_ROI[sidx][roi_idx][0][vox] < thresh:\n",
    "                lh_betas_by_repeat_by_ROI[sidx][roi_idx][0][:,vox]=np.nan\n",
    "                lh_betas_by_repeat_by_ROI[sidx][roi_idx][1][:,vox]=np.nan\n",
    "                lh_betas_by_repeat_by_ROI[sidx][roi_idx][2][:,vox]=np.nan    \n",
    "\n",
    "                thresh_vox = np.zeros((len(subjid), len(ROI_names)-1))\n",
    "                \n",
    "#trim out nans\n",
    "for sidx, sid in enumerate(subjid):   \n",
    "    for roi_idx in range(len(ROI_names)-1): \n",
    "        for r in range(n_repeats):\n",
    "            temp = lh_betas_by_repeat_by_ROI[sidx][roi_idx][r]\n",
    "            trimmed = temp[:,~np.all(np.isnan(temp), axis=0)]\n",
    "\n",
    "            lh_betas_by_repeat_by_ROI[sidx][roi_idx][r] = trimmed\n",
    "        thresh_vox[sidx,roi_idx] = trimmed.shape[1]\n",
    "\n",
    "#gather number of remaining voxels for each ROI and subj\n",
    "vox = np.zeros((len(ROI_names)-1, len(subjid)))\n",
    "for roi_idx in range(len(ROI_names)-1):\n",
    "    vox[roi_idx,:] = [lh_betas_by_repeat_by_ROI[sidx][roi_idx][0].shape[1] for sidx, sid in enumerate(subjid)]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RSMS for all the ROIs, repeats and subjects\n",
    "\n",
    "tril_flat_shape = int((lh_betas_by_repeat_by_ROI[0][0][0].shape[0]**2/2) - (lh_betas_by_repeat_by_ROI[0][0][0].shape[0]/2))\n",
    "lh_flat_rsm = np.zeros((len(subjid),len(ROI_names)-1, tril_flat_shape, n_repeats))\n",
    "rsm = np.zeros((len(subjid),len(ROI_names)-1,n_repeats,lh_betas_by_repeat_by_ROI[0][0][0].shape[0],lh_betas_by_repeat_by_ROI[0][0][0].shape[0]))\n",
    "\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    \n",
    "    for roi_idx in range(len(ROI_names)-1):\n",
    "        voxels = np.min(vox[roi_idx,:])\n",
    "        \n",
    "        for r in range(n_repeats):\n",
    "            rsm[sidx,roi_idx,r,:,:] = np.corrcoef(lh_betas_by_repeat_by_ROI[sidx][roi_idx][r])\n",
    "            lower = np.tril(rsm[sidx,roi_idx,r,:,:], -1).T.ravel() #only need lower triangle without diagonal\n",
    "            lh_flat_rsm[sidx, roi_idx, :,r] = lower[lower != 0] #flatten into vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare hemispheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_trial_order = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "r2_trial_order = [0, 1, 2, 0, 1, 2, 0, 1, 2]\n",
    "\n",
    "#don't use same trials when same subject\n",
    "ss_r1_trial_order = [0, 0, 1, 1, 2, 2]\n",
    "ss_r2_trial_order = [1, 2, 0, 2, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_combs = len(subjid) * (len(ROI_names)-1)\n",
    "mega_matrix = np.zeros((total_combs,total_combs))\n",
    "total_rsms_sh_rh = np.zeros((len(subjid),len(ROI_names)-1))\n",
    "total_rsms_sh_lh = np.zeros((len(subjid),len(ROI_names)-1))\n",
    "total_rsms_across_hemis = np.zeros((len(subjid),len(ROI_names)-1))\n",
    "\n",
    "\n",
    "for i in range(total_combs): #rows - i.e. model candidate\n",
    "    roi_idx1 = i%7 #roi\n",
    "    sidx1 = i//7 #subject\n",
    "    \n",
    "    #right hemisphere split half\n",
    "    split_half = np.zeros((3))\n",
    "    split_half = [stats.pearsonr(rh_flat_rsm[sidx1,roi_idx1,:,0],rh_flat_rsm[sidx1,roi_idx1,:,1])[0],\n",
    "                  stats.pearsonr(rh_flat_rsm[sidx1,roi_idx1,:,0],rh_flat_rsm[sidx1,roi_idx1,:,2])[0],\n",
    "                  stats.pearsonr(rh_flat_rsm[sidx1,roi_idx1,:,1],rh_flat_rsm[sidx1,roi_idx1,:,2])[0]]\n",
    "    total_rsms_sh_rh[sidx1,roi_idx1]= np.mean(split_half)\n",
    "    \n",
    "    #left hemisphere split half\n",
    "    split_half = np.zeros((3))\n",
    "    split_half = [stats.pearsonr(lh_flat_rsm[sidx1,roi_idx1,:,0],lh_flat_rsm[sidx1,roi_idx1,:,1])[0],\n",
    "                  stats.pearsonr(lh_flat_rsm[sidx1,roi_idx1,:,0],lh_flat_rsm[sidx1,roi_idx1,:,2])[0],\n",
    "                  stats.pearsonr(lh_flat_rsm[sidx1,roi_idx1,:,1],lh_flat_rsm[sidx1,roi_idx1,:,2])[0]]\n",
    "    total_rsms_sh_lh[sidx1,roi_idx1]= np.mean(split_half)\n",
    "    \n",
    "    for j in range(total_combs): #columns - i.e. target data\n",
    "        roi_idx2 = j%7 #roi\n",
    "        sidx2 = j//7 #subject\n",
    "        \n",
    "        if (sidx1 == sidx2) and (roi_idx1 == roi_idx2): #within subject and roi only\n",
    "            rsm_corr = np.zeros((6))\n",
    "            for r in range(6):\n",
    "                rsm_corr[r] = np.absolute(stats.pearsonr(rh_flat_rsm[sidx1,roi_idx1,:,ss_r1_trial_order[r]],\n",
    "                                                         lh_flat_rsm[sidx2,roi_idx2,:,ss_r2_trial_order[r]])[0])\n",
    "            total_rsms_across_hemis[sidx1, roi_idx1] = np.mean(rsm_corr)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rsms_across_hemis[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rsms_sh_rh[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rsms_sh_lh[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_rsms_across_hemis, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_rsms_sh_rh, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(total_rsms_sh_lh, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = ['Early', 'Midventral', 'Midlateral', 'Midparietal', 'Ventral', 'Lateral', 'Parietal']\n",
    "total_means = np.mean(total_rsms_across_hemis, axis=0)\n",
    "rh_means = np.mean(total_rsms_sh_rh, axis=0)\n",
    "lh_means = np.mean(total_rsms_sh_lh, axis=0)\n",
    "\n",
    "x = np.arange(len(labels))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,5))\n",
    "\n",
    "rects1 = ax.bar(x - 1.01*width, lh_means, width, label='Left', color='navy')\n",
    "rects2 = ax.bar(x, rh_means, width, label='Right', color='blue')\n",
    "rects3 = ax.bar(x + 1.01*width, total_means, width, label='Across', color='orchid')\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Pearsons r',fontsize=20)\n",
    "ax.set_title('RSM correlation within and across hemispheres ('+str(thresh*100)+'% threshold)',fontsize=20)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(round(height,2)),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.ylim(0,.6)\n",
    "plt.show()\n",
    "\n",
    "fig.savefig('../../../results/figures/hemi_comparison_voxThresh' + str(int(thresh*100)) + '.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
