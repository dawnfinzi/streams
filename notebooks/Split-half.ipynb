{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate and save maps of split-half reliability for each voxel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split-half reliability here is defined as the average correlation across the three combinations of pairs of repeats (i.e. presentation 1 correlated with presentation 2, presentation 2 with presentation 3, presentation 1 with presentation 3). The numbers of images presented 3 times varies slightly across participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import nibabel as nibabel\n",
    "import pandas as pd\n",
    "import nibabel.freesurfer.mghformat as mgh\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../data/'\n",
    "subjid = ['01', '02', '03', '04', '05', '06', '07', '08']\n",
    "ROI_names = ['Unknown', 'Early', 'Midventral', 'Midlateral', 'Midparietal', 'Ventral', 'Lateral', 'Parietal']\n",
    "n_repeats = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = []\n",
    "max_session = np.zeros(len(subjid))\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    \n",
    "    data = pd.read_csv('../../../data/nsddata/ppdata/subj'+ sid +'/behav/responses.tsv', sep='\\t')\n",
    "    \n",
    "    max_session[sidx] = np.max(np.array(data['SESSION'])) \n",
    "    \n",
    "    all_ids.append(np.array(data['73KID']))\n",
    "    \n",
    "    #shared_mask.append(np.isin(all_ids[sidx],sharedix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([46003, 61883,   829, ..., 53168,  1944,  5034]),\n",
       " array([46003, 42020, 22500, ..., 61376, 42648, 69768]),\n",
       " array([46003, 19257, 36386, ..., 56937, 28438, 42959]),\n",
       " array([46003, 23082,  8031, ..., 67073, 12918,  3388]),\n",
       " array([46003,  5737,  9204, ..., 44063, 53238, 54913]),\n",
       " array([46003, 21397, 18925, ..., 58176, 18756, 46521]),\n",
       " array([46003, 16507,  9387, ..., 34541, 31244, 55231]),\n",
       " array([46003, 57484, 41828, ..., 54394,    30, 23135])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_reps = []\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    vals, idx_start, count = np.unique(all_ids[sidx], return_counts=True,\n",
    "                                    return_index=True)\n",
    "    which_reps.append(vals[count == n_repeats])\n",
    "    \n",
    "least_trials = min(which_reps, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   14,    28,    72, ..., 72986, 72993, 73000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_reps[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_3reps = []\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    \n",
    "    data = pd.read_csv('../../../data/nsddata/ppdata/subj'+ sid +'/behav/responses.tsv', sep='\\t')\n",
    "    \n",
    "    mask_3reps.append(np.isin(all_ids[sidx],which_reps[sidx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mask_3reps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n"
     ]
    }
   ],
   "source": [
    "#right hemisphere\n",
    "\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    \n",
    "    print(sid)\n",
    "    mask = mask_3reps[sidx]\n",
    "    \n",
    "    #get all betas across all sessions\n",
    "    for sess in range(1,int(max_session[sidx])+1):\n",
    "        \n",
    "        if(sess < 10):\n",
    "            idx = '0' + str(sess)\n",
    "        else:\n",
    "            idx = str(sess)\n",
    "\n",
    "        raw_betas = h5py.File(data_dir+'nsddata_betas/ppdata/subj'+ sid +'/nativesurface/betas_fithrf_GLMdenoise_RR/rh.betas_session'+idx+'.hdf5', 'r')\n",
    "        #betas = raw_betas['betas'][:]/300 #takes too much memory and conversion not necc for split half calcs\n",
    "        \n",
    "        sess_betas = raw_betas['betas'][:][mask[(sess-1)*750:sess*750]]\n",
    "        del raw_betas\n",
    "\n",
    "        if(sess==1):\n",
    "            subj_betas = sess_betas\n",
    "        else:\n",
    "            subj_betas = np.concatenate((subj_betas, sess_betas))\n",
    "            \n",
    "        del sess_betas\n",
    "    \n",
    "    #sort betas into 1st, 2nd and 3rd presentations\n",
    "    masked_ids = all_ids[sidx][mask]\n",
    "    arr1inds = masked_ids.argsort()\n",
    "    sorted_betas = subj_betas[arr1inds[::-1]]\n",
    "    del subj_betas\n",
    "\n",
    "    betas_by_repeat = []\n",
    "    for r in range(n_repeats):\n",
    "        betas_by_repeat.insert(r,sorted_betas[r::3])\n",
    "\n",
    "    del sorted_betas\n",
    "\n",
    "    n_vox = betas_by_repeat[0].shape[1]\n",
    "    t1 = [0, 0, 1]\n",
    "    t2 = [1, 2, 2]\n",
    "    #calculate split-half reliability\n",
    "    corrvals = np.zeros((n_vox,3))\n",
    "    for vox in range(n_vox):\n",
    "        for r in range(3):\n",
    "            corrval = stats.pearsonr(betas_by_repeat[t1[r]][:,vox],\n",
    "                                     betas_by_repeat[t2[r]][:,vox])[0]\n",
    "            corrvals[vox, r] = corrval\n",
    "\n",
    "\n",
    "    avg_corrvals = np.mean(corrvals, axis=1)\n",
    "    sem_corrvals = stats.sem(corrvals, axis=1)\n",
    "\n",
    "    #create dict for matlab\n",
    "    split_half = {}\n",
    "    split_half['mean'] = avg_corrvals\n",
    "    split_half['sem'] = sem_corrvals\n",
    "\n",
    "    #save out\n",
    "    save_dir = '../../../local_data/freesurfer/subj' + sid \n",
    "    scipy.io.savemat(save_dir + '/rh_split_half.mat', split_half)\n",
    "    \n",
    "    #cleanup\n",
    "    del corrvals, avg_corrvals, sem_corrvals, split_half, betas_by_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n"
     ]
    }
   ],
   "source": [
    "#left hemisphere\n",
    "\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    \n",
    "    print(sid)\n",
    "    mask = mask_3reps[sidx]\n",
    "    \n",
    "    #get all betas across all sessions\n",
    "    for sess in range(1,int(max_session[sidx])+1):\n",
    "        \n",
    "        if(sess < 10):\n",
    "            idx = '0' + str(sess)\n",
    "        else:\n",
    "            idx = str(sess)\n",
    "\n",
    "        raw_betas = h5py.File(data_dir+'nsddata_betas/ppdata/subj'+ sid +'/nativesurface/betas_fithrf_GLMdenoise_RR/lh.betas_session'+idx+'.hdf5', 'r')\n",
    "        #betas = raw_betas['betas'][:]/300 #takes too much memory and conversion not necc for split half calcs\n",
    "        \n",
    "        sess_betas = raw_betas['betas'][:][mask[(sess-1)*750:sess*750]]\n",
    "        del raw_betas\n",
    "\n",
    "        if(sess==1):\n",
    "            subj_betas = sess_betas\n",
    "        else:\n",
    "            subj_betas = np.concatenate((subj_betas, sess_betas))\n",
    "            \n",
    "        del sess_betas\n",
    "    \n",
    "    #sort betas into 1st, 2nd and 3rd presentations\n",
    "    masked_ids = all_ids[sidx][mask]\n",
    "    arr1inds = masked_ids.argsort()\n",
    "    sorted_betas = subj_betas[arr1inds[::-1]]\n",
    "    del subj_betas\n",
    "\n",
    "    betas_by_repeat = []\n",
    "    for r in range(n_repeats):\n",
    "        betas_by_repeat.insert(r,sorted_betas[r::3])\n",
    "\n",
    "    del sorted_betas\n",
    "\n",
    "    n_vox = betas_by_repeat[0].shape[1]\n",
    "    t1 = [0, 0, 1]\n",
    "    t2 = [1, 2, 2]\n",
    "    #calculate split-half reliability\n",
    "    corrvals = np.zeros((n_vox,3))\n",
    "    for vox in range(n_vox):\n",
    "        for r in range(3):\n",
    "            corrval = stats.pearsonr(betas_by_repeat[t1[r]][:,vox],\n",
    "                                     betas_by_repeat[t2[r]][:,vox])[0]\n",
    "            corrvals[vox, r] = corrval\n",
    "\n",
    "\n",
    "    avg_corrvals = np.mean(corrvals, axis=1)\n",
    "    sem_corrvals = stats.sem(corrvals, axis=1)\n",
    "\n",
    "    #create dict for matlab\n",
    "    split_half = {}\n",
    "    split_half['mean'] = avg_corrvals\n",
    "    split_half['sem'] = sem_corrvals\n",
    "\n",
    "    #save out\n",
    "    save_dir = '../../../local_data/freesurfer/subj' + sid \n",
    "    scipy.io.savemat(save_dir + '/lh_split_half.mat', split_half)\n",
    "    \n",
    "    #cleanup\n",
    "    del corrvals, avg_corrvals, sem_corrvals, split_half, betas_by_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
