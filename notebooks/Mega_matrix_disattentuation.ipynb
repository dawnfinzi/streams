{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mega matrix with disattenuation applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import nibabel as nibabel\n",
    "import pandas as pd\n",
    "import nibabel.freesurfer.mghformat as mgh\n",
    "import scipy.io\n",
    "import itertools \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../data/'\n",
    "local_data_dir = '../../../local_data/'\n",
    "\n",
    "subjid = ['01', '02', '03', '04', '05', '06', '07', '08']\n",
    "ROI_names = ['Unknown', 'Early', 'Midventral', 'Midlateral', 'Midparietal', 'Ventral', 'Lateral', 'Parietal']\n",
    "n_repeats = 3\n",
    "\n",
    "#threshold for voxels (based on split-half reliability)\n",
    "thresh = 0 #0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ROI data\n",
    "rh_streams = []\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    mgh_file = mgh.load(data_dir+'nsddata/freesurfer/subj'+ sid +'/label/rh.streams.mgz')\n",
    "    rh_streams.append(mgh_file.get_fdata()[:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get voxel level split-half reliability data\n",
    "reliability = []\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    \n",
    "    sh_dir = local_data_dir + 'freesurfer/subj' + sid + '/rh_split_half.mat'\n",
    "    sh = scipy.io.loadmat(sh_dir)\n",
    "    \n",
    "    reliability.append(sh['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get organized z-scored betas\n",
    "with open(local_data_dir + 'processed/rh_betas_by_repeat_by_ROI_zscore.data', 'rb') as filehandle:\n",
    "    # read the data as binary data stream\n",
    "    rh_betas_by_repeat_by_ROI = pickle.load(filehandle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace voxels with split-half reliability < thresh with NaNs and then trim those from data structure\n",
    "\n",
    "sh_by_ROI = [[[] for j in range(len(ROI_names)-1)] for i in range(len(subjid))]\n",
    "total_vox = np.zeros((len(subjid), len(ROI_names)-1))\n",
    "\n",
    "#organize\n",
    "for sidx, sid in enumerate(subjid):  \n",
    "    for roi_idx in range(len(ROI_names)-1):       \n",
    "        sh_by_ROI[sidx][roi_idx]=reliability[sidx][:,rh_streams[sidx] == roi_idx+1]\n",
    "        total_vox[sidx,roi_idx] = len(sh_by_ROI[sidx][roi_idx][0])\n",
    "\n",
    "#convert to nans\n",
    "for sidx, sid in enumerate(subjid):  \n",
    "    for roi_idx in range(len(ROI_names)-1): \n",
    "        for vox in range(len(sh_by_ROI[sidx][roi_idx][0])):\n",
    "            if sh_by_ROI[sidx][roi_idx][0][vox] < thresh:\n",
    "                rh_betas_by_repeat_by_ROI[sidx][roi_idx][0][:,vox]=np.nan\n",
    "                rh_betas_by_repeat_by_ROI[sidx][roi_idx][1][:,vox]=np.nan\n",
    "                rh_betas_by_repeat_by_ROI[sidx][roi_idx][2][:,vox]=np.nan    \n",
    "\n",
    "                thresh_vox = np.zeros((len(subjid), len(ROI_names)-1))\n",
    "                \n",
    "#trim out nans\n",
    "for sidx, sid in enumerate(subjid):   \n",
    "    for roi_idx in range(len(ROI_names)-1): \n",
    "        for r in range(n_repeats):\n",
    "            temp = rh_betas_by_repeat_by_ROI[sidx][roi_idx][r]\n",
    "            trimmed = temp[:,~np.all(np.isnan(temp), axis=0)]\n",
    "\n",
    "            rh_betas_by_repeat_by_ROI[sidx][roi_idx][r] = trimmed\n",
    "        thresh_vox[sidx,roi_idx] = trimmed.shape[1]\n",
    "\n",
    "#gather number of remaining voxels for each ROI and subj\n",
    "vox = np.zeros((len(ROI_names)-1, len(subjid)))\n",
    "for roi_idx in range(len(ROI_names)-1):\n",
    "    vox[roi_idx,:] = [rh_betas_by_repeat_by_ROI[sidx][roi_idx][0].shape[1] for sidx, sid in enumerate(subjid)]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RSMS for all the ROIs, repeats and subjects\n",
    "\n",
    "tril_flat_shape = int((rh_betas_by_repeat_by_ROI[0][0][0].shape[0]**2/2) - (rh_betas_by_repeat_by_ROI[0][0][0].shape[0]/2))\n",
    "flat_rsm = np.zeros((len(subjid),len(ROI_names)-1, tril_flat_shape, n_repeats))\n",
    "rsm = np.zeros((len(subjid),len(ROI_names)-1,n_repeats,rh_betas_by_repeat_by_ROI[0][0][0].shape[0],rh_betas_by_repeat_by_ROI[0][0][0].shape[0]))\n",
    "\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    \n",
    "    for roi_idx in range(len(ROI_names)-1):\n",
    "        voxels = np.min(vox[roi_idx,:])\n",
    "        \n",
    "        for r in range(n_repeats):\n",
    "            rsm[sidx,roi_idx,r,:,:] = np.corrcoef(rh_betas_by_repeat_by_ROI[sidx][roi_idx][r])\n",
    "            lower = np.tril(rsm[sidx,roi_idx,r,:,:], -1).T.ravel() #only need lower triangle without diagonal\n",
    "            flat_rsm[sidx, roi_idx, :,r] = lower[lower != 0] #flatten into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_trial_order = [0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "r2_trial_order = [0, 1, 2, 0, 1, 2, 0, 1, 2]\n",
    "\n",
    "#don't use same trials when same subject\n",
    "ss_r1_trial_order = [0, 0, 1, 1, 2, 2]\n",
    "ss_r2_trial_order = [1, 2, 0, 2, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_combs = len(subjid) * (len(ROI_names)-1)\n",
    "mega_matrix = np.zeros((total_combs,total_combs))\n",
    "\n",
    "for i in range(total_combs): #rows - i.e. model candidate\n",
    "    roi_idx1 = i%7 #roi\n",
    "    sidx1 = i//7 #subject\n",
    "    \n",
    "    split_half = np.zeros((3))\n",
    "    split_half = [np.absolute(stats.pearsonr(flat_rsm[sidx1,roi_idx1,:,0],flat_rsm[sidx1,roi_idx1,:,1])[0]),\n",
    "                  np.absolute(stats.pearsonr(flat_rsm[sidx1,roi_idx1,:,0],flat_rsm[sidx1,roi_idx1,:,2])[0]),\n",
    "                  np.absolute(stats.pearsonr(flat_rsm[sidx1,roi_idx1,:,1],flat_rsm[sidx1,roi_idx1,:,2])[0])]\n",
    "    NC_model = np.mean(split_half) * 100\n",
    "    \n",
    "    for j in range(total_combs): #columns - i.e. target data\n",
    "        roi_idx2 = j%7 #roi\n",
    "        sidx2 = j//7 #subject\n",
    "        \n",
    "        split_half = np.zeros((3))\n",
    "        split_half = [np.absolute(stats.pearsonr(flat_rsm[sidx2,roi_idx2,:,0],flat_rsm[sidx2,roi_idx2,:,1])[0]),\n",
    "                      np.absolute(stats.pearsonr(flat_rsm[sidx2,roi_idx2,:,0],flat_rsm[sidx2,roi_idx2,:,2])[0]),\n",
    "                      np.absolute(stats.pearsonr(flat_rsm[sidx2,roi_idx2,:,1],flat_rsm[sidx2,roi_idx2,:,2])[0])]\n",
    "        NC_target = np.mean(split_half) * 100\n",
    "        \n",
    "        if (sidx1 == sidx2): #within subject\n",
    "            rsm_corr = np.zeros((6))\n",
    "            for r in range(6):\n",
    "                rsm_corr[r] = np.absolute(stats.pearsonr(flat_rsm[sidx1,roi_idx1,:,ss_r1_trial_order[r]],\n",
    "                                                         flat_rsm[sidx2,roi_idx2,:,ss_r2_trial_order[r]])[0])\n",
    "            mega_matrix[i,j] = np.mean(rsm_corr) * np.sqrt(100/NC_model) * np.sqrt(100/NC_target)\n",
    "        else: #between subject\n",
    "            rsm_corr = np.zeros((9))\n",
    "            for r in range(9):\n",
    "                rsm_corr[r] = np.absolute(stats.pearsonr(flat_rsm[sidx1,roi_idx1,:,r1_trial_order[r]],\n",
    "                                                         flat_rsm[sidx2,roi_idx2,:,r2_trial_order[r]])[0])\n",
    "            mega_matrix[i,j] = np.mean(rsm_corr) * np.sqrt(100/NC_model) * np.sqrt(100/NC_target)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(mega_matrix,\n",
    "           cmap='magma')\n",
    "\n",
    "x_labels = ['Subj01', 'Subj02', 'Subj03', 'Subj04', 'Subj05', 'Subj06', 'Subj07', 'Subj08']\n",
    "y_labels = ['Early', 'Midventral', 'Midlateral', 'Midparietal', 'Ventral', 'Lateral', 'Parietal']\n",
    "\n",
    "x_ticks = np.arange(0+3, 56+3,7)\n",
    "plt.xticks(x_ticks, x_labels, fontsize=20)\n",
    "plt.tick_params(axis='both', which='major', labelbottom = False, bottom=False, top = False, labeltop=True)\n",
    "\n",
    "y_ticks = np.arange(0, 56)\n",
    "plt.yticks(y_ticks, np.tile(y_labels, 8), fontsize='large')\n",
    "colors = ['#66b3ff','#3399ff','#0066cc','#0059b3','#00264d','#001a33','#000000']\n",
    "for i in range(56):\n",
    "    r = i%7\n",
    "    plt.gca().get_yticklabels()[i].set_color(colors[r])\n",
    "\n",
    "plt.axvline(x=6.5, c='w')\n",
    "plt.axvline(x=13.5, c='w')\n",
    "plt.axvline(x=20.5, c='w')\n",
    "plt.axvline(x=27.5, c='w')\n",
    "plt.axvline(x=34.5, c='w')\n",
    "plt.axvline(x=41.5, c='w')\n",
    "plt.axvline(x=48.5, c='w')\n",
    "\n",
    "\n",
    "plt.axhline(y=6.5, c='w')\n",
    "plt.axhline(y=13.5, c='w')\n",
    "plt.axhline(y=20.5, c='w')\n",
    "plt.axhline(y=27.5, c='w')\n",
    "plt.axhline(y=34.5, c='w')\n",
    "plt.axhline(y=41.5, c='w')\n",
    "plt.axhline(y=48.5, c='w')\n",
    "\n",
    "plt.clim(0,1)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)\n",
    "\n",
    "plt.savefig('../../../results/figures/megaMatrix_voxThresh' + str(int(thresh*100)) + '_adjusted_both_rh.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_idx = np.arange(0,len(subjid))\n",
    "subj_combs = list(itertools.combinations(subj_idx, 2))\n",
    "\n",
    "print(subj_combs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vent2vent = []\n",
    "lat2lat = []\n",
    "vent2lat = []\n",
    "lat2vent = []\n",
    "\n",
    "for i in range(total_combs): #rows - i.e. model candidate\n",
    "    roi_idx1 = i%7 #roi\n",
    "    sidx1 = i//7 #subject\n",
    "    \n",
    "    for j in range(total_combs): #columns - i.e. target data\n",
    "        roi_idx2 = j%7 #roi\n",
    "        sidx2 = j//7 #subject\n",
    "        \n",
    "        if (sum([(sidx1==comb[0] and sidx2==comb[1]) for comb in subj_combs]))>0: #check that we're in lower triangle\n",
    "            \n",
    "            if (roi_idx1 == 4 and roi_idx2 == 4):\n",
    "                vent2vent.append(mega_matrix[i,j])\n",
    "            elif (roi_idx1 == 5 and roi_idx2 == 5):\n",
    "                lat2lat.append(mega_matrix[i,j])\n",
    "            elif (roi_idx1 == 4 and roi_idx2 == 5):\n",
    "                vent2lat.append(mega_matrix[i,j])\n",
    "            elif (roi_idx1 == 5 and roi_idx2 == 4):\n",
    "                lat2vent.append(mega_matrix[i,j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(vent2vent))\n",
    "print(np.mean(lat2lat))\n",
    "print(np.mean([vent2lat, lat2vent]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [np.mean(vent2vent), np.mean(lat2lat), np.mean(np.hstack((vent2lat, lat2vent)))]\n",
    "error = [stats.sem(vent2vent, axis=0), stats.sem(lat2vent, axis=0), stats.sem(np.hstack((vent2lat, lat2vent)), axis=0)]\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "xlocations = np.array(range(3))+.1\n",
    "width = 0.5\n",
    "plt.bar(xlocations, d, yerr=error, width=width, color = ['r','r','b'], alpha = .6)\n",
    "plt.xticks(xlocations, ['Vent2Vent', 'Lat2Lat', 'Cross'])\n",
    "plt.xlim(-0.5, xlocations[-1]+width)\n",
    "plt.ylim(0,1)\n",
    "#plt.title(\"Average RSM correlation by area\")\n",
    "plt.gca().get_yaxis().tick_left()\n",
    "plt.gca().get_xaxis().tick_bottom()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## not guaranteed by analysis - for example, subj 1 ventral predicts other subj 2 mid ventral \n",
    "## better than subj 1 midventral predicts subj 2 midventral\n",
    "\n",
    "midvent2midvent = []\n",
    "midlat2midlat = []\n",
    "\n",
    "vent2midvent = []\n",
    "vent2midlat = []\n",
    "\n",
    "for i in range(total_combs): #rows - i.e. model candidate\n",
    "    roi_idx1 = i%7 #roi\n",
    "    sidx1 = i//7 #subject\n",
    "    \n",
    "    for j in range(total_combs): #columns - i.e. target data\n",
    "        roi_idx2 = j%7 #roi\n",
    "        sidx2 = j//7 #subject\n",
    "        \n",
    "        if (sum([(sidx1==comb[0] and sidx2==comb[1]) for comb in subj_combs]))>0: #check that we're in lower triangle\n",
    "            \n",
    "            if (roi_idx1 == 1 and roi_idx2 == 1):\n",
    "                midvent2midvent.append(mega_matrix[i,j])\n",
    "            elif (roi_idx1 == 2 and roi_idx2 == 2):\n",
    "                midlat2midlat.append(mega_matrix[i,j])\n",
    "            elif (roi_idx1 == 1 and roi_idx2 == 4) or (roi_idx1 == 4 and roi_idx2 == 1):\n",
    "                vent2midvent.append(mega_matrix[i,j])\n",
    "            elif (roi_idx1 == 2 and roi_idx2 == 4) or (roi_idx1 == 4 and roi_idx2 == 2):\n",
    "                vent2midlat.append(mega_matrix[i,j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(midvent2midvent))\n",
    "print(np.mean(vent2midvent))\n",
    "\n",
    "print(np.mean(midlat2midlat))\n",
    "print(np.mean(vent2midlat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(midvent2midvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
