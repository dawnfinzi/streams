{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test parcellation approach with subj05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import nibabel as nibabel\n",
    "import pandas as pd\n",
    "import nibabel.freesurfer.mghformat as mgh\n",
    "import scipy.io\n",
    "import itertools \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "utils_dir = '/oak/stanford/groups/kalanit/biac2/kgs/projects/Dawn/NSD/code/streams/utils/'\n",
    "sys.path.append(utils_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rsm_utils import get_flat_lower_tri, make_flat_rsms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../../data/'\n",
    "local_data_dir = '../../../local_data/'\n",
    "\n",
    "subjid = ['06']\n",
    "n_repeats = 3\n",
    "\n",
    "#threshold for voxels (based on split-half reliability)\n",
    "thresh = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ROI data\n",
    "rh_parcels = []\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    mgh_file = mgh.load(local_data_dir+'freesurfer/subj'+ sid +'/rh.tessellate_500.mgz')\n",
    "    rh_parcels.append(mgh_file.get_fdata()[:,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rois = int(np.max(rh_parcels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_rois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get voxel level split-half reliability data\n",
    "reliability = []\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    \n",
    "    sh_dir = local_data_dir + 'freesurfer/subj' + sid + '/rh_split_half.mat'\n",
    "    sh = scipy.io.loadmat(sh_dir)\n",
    "    \n",
    "    reliability.append(sh['mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's organize by ROI \n",
    "sh_by_ROI = [[[] for j in range(num_rois)] for i in range(len(subjid))]\n",
    "total_vox = np.zeros((len(subjid), num_rois))\n",
    "\n",
    "for sidx, sid in enumerate(subjid):  \n",
    "    for roi_idx in range(num_rois):       \n",
    "        sh_by_ROI[sidx][roi_idx]=reliability[sidx][:,rh_parcels[sidx] == roi_idx+1]\n",
    "        total_vox[sidx,roi_idx] = len(sh_by_ROI[sidx][roi_idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_rois = np.array([np.sum(sh_by_ROI[0][r]>.1) for r in range(num_rois)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.923728813559322"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(thresh_rois>1)/num_rois #percent rois above thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids = []\n",
    "max_session = np.zeros(len(subjid))\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    \n",
    "    data = pd.read_csv(data_dir+'nsddata/ppdata/subj'+ sid +'/behav/responses.tsv', sep='\\t')\n",
    "    \n",
    "    max_session[sidx] = np.max(np.array(data['SESSION'])) \n",
    "    \n",
    "    all_ids.append(np.array(data['73KID']))\n",
    "    \n",
    "    #shared_mask.append(np.isin(all_ids[sidx],sharedix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "which_reps = []\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    vals, idx_start, count = np.unique(all_ids[sidx], return_counts=True,\n",
    "                                    return_index=True)\n",
    "    which_reps.append(vals[count == n_repeats])\n",
    "    \n",
    "least_trials = min(which_reps, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_nums_3reps = []\n",
    "mask_3reps = []\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    \n",
    "    data = pd.read_csv(data_dir+'nsddata/ppdata/subj'+ sid +'/behav/responses.tsv', sep='\\t')\n",
    "    \n",
    "    mask_3reps.append(np.isin(all_ids[sidx],which_reps[sidx]))\n",
    "    id_nums_3reps.append(np.array(data['73KID'])[mask_3reps[sidx]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1inds = id_nums_3reps[sidx].argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#right hemisphere\n",
    "betas_by_ROI = [[] for j in range(num_rois)]\n",
    "\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    \n",
    "    print(sidx)\n",
    "    mask = mask_3reps[sidx]\n",
    "    sorted_betas = []\n",
    "    \n",
    "    #get all betas across all sessions\n",
    "    for sess in range(1,int(max_session[sidx])+1):\n",
    "        print(sess)\n",
    "                \n",
    "        if(sess < 10):\n",
    "            idx = '0' + str(sess)\n",
    "        else:\n",
    "            idx = str(sess)\n",
    "\n",
    "        raw_betas = h5py.File(local_data_dir+'freesurfer/subj'+sid+'/betas/rh.zscore_betas_session'+idx+'.hdf5','r')\n",
    "\n",
    "        sess_betas = raw_betas['zscore_betas'][:][mask[(sess-1)*750:sess*750]]\n",
    "        del raw_betas\n",
    "        \n",
    "        if(sess==1):\n",
    "            for roi_idx in range(num_rois):\n",
    "                betas_by_ROI[roi_idx] = sess_betas[:,rh_parcels[sidx] == roi_idx+1]\n",
    "        else:\n",
    "            for roi_idx in range(num_rois):\n",
    "                betas_by_ROI[roi_idx] = np.append(betas_by_ROI[roi_idx],sess_betas[:,rh_parcels[sidx] == roi_idx+1],axis=0)\n",
    "        \n",
    "        del sess_betas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_by_repeat_by_ROI = [[[] for j in range(num_rois)] for i in range(len(subjid))]\n",
    "for sidx, sid in enumerate(subjid):\n",
    "    for roi_idx in range(num_rois):  \n",
    "        \n",
    "        sorted_betas = betas_by_ROI[roi_idx][arr1inds[::-1]]\n",
    "        \n",
    "        for r in range(n_repeats):\n",
    "            betas_by_repeat_by_ROI[sidx][roi_idx].insert(r,sorted_betas[r::3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas_by_repeat_by_ROI[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace voxels with split-half reliability < thresh with NaNs and then trim those from data structure\n",
    "\n",
    "#convert to nans\n",
    "for sidx, sid in enumerate(subjid):  \n",
    "    for roi_idx in range(num_rois): \n",
    "        for vox in range(len(sh_by_ROI[sidx][roi_idx][0])):\n",
    "            if sh_by_ROI[sidx][roi_idx][0][vox] < thresh:\n",
    "                betas_by_repeat_by_ROI[sidx][roi_idx][0][:,vox]=np.nan\n",
    "                betas_by_repeat_by_ROI[sidx][roi_idx][1][:,vox]=np.nan\n",
    "                betas_by_repeat_by_ROI[sidx][roi_idx][2][:,vox]=np.nan    \n",
    "#trim out nans\n",
    "for sidx, sid in enumerate(subjid):   \n",
    "    for roi_idx in range(num_rois): \n",
    "        for r in range(n_repeats):\n",
    "            temp = betas_by_repeat_by_ROI[sidx][roi_idx][r]\n",
    "            trimmed = temp[:,~np.all(np.isnan(temp), axis=0)]\n",
    "\n",
    "            betas_by_repeat_by_ROI[sidx][roi_idx][r] = trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del sorted_betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del betas_by_ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trimmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create RSMS for all the ROIs, repeats and subjects\n",
    "tril_flat_shape = int((betas_by_repeat_by_ROI[0][0][0].shape[0]**2/2) - (betas_by_repeat_by_ROI[0][0][0].shape[0]/2))\n",
    "flat_rsm_r1 = np.zeros((num_rois, tril_flat_shape))\n",
    "flat_rsm_r2 = np.zeros((num_rois, tril_flat_shape))\n",
    "flat_rsm_r3 = np.zeros((num_rois, tril_flat_shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sidx = 0\n",
    "for roi_idx in range(num_rois):\n",
    "        \n",
    "    rsm = np.corrcoef(betas_by_repeat_by_ROI[sidx][roi_idx][0])\n",
    "    flat_rsm_r1[roi_idx, :] = get_flat_lower_tri(rsm,diagonal=False)\n",
    "\n",
    "    rsm = np.corrcoef(betas_by_repeat_by_ROI[sidx][roi_idx][1])\n",
    "    flat_rsm_r2[roi_idx, :] = get_flat_lower_tri(rsm,diagonal=False)\n",
    "\n",
    "    rsm = np.corrcoef(betas_by_repeat_by_ROI[sidx][roi_idx][2])\n",
    "    flat_rsm_r3[roi_idx, :] = get_flat_lower_tri(rsm,diagonal=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_rsm_r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_trial_order = [0, 0, 1, 1, 2, 2]\n",
    "r2_trial_order = [1, 2, 0, 2, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del betas_by_repeat_by_ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del rsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_matrix = np.zeros((num_rois,num_rois))\n",
    "\n",
    "for roi_idx1 in range(num_rois): #rows - i.e. model candidate\n",
    "    \n",
    "    split_half = np.zeros((3))\n",
    "    split_half = [stats.pearsonr(flat_rsm_r1[roi_idx1,:],flat_rsm_r2[roi_idx1,:])[0],\n",
    "                  stats.pearsonr(flat_rsm_r1[roi_idx1,:],flat_rsm_r3[roi_idx1,:])[0],\n",
    "                  stats.pearsonr(flat_rsm_r2[roi_idx1,:],flat_rsm_r3[roi_idx1,:])[0]]\n",
    "    NC_model = np.mean(split_half) * 100\n",
    "    \n",
    "    for roi_idx2 in range(num_rois): #columns - i.e. target data\n",
    "        \n",
    "        split_half = np.zeros((3))\n",
    "        split_half = [stats.pearsonr(flat_rsm_r1[roi_idx2,:],flat_rsm_r2[roi_idx2,:])[0],\n",
    "                      stats.pearsonr(flat_rsm_r1[roi_idx2,:],flat_rsm_r3[roi_idx2,:])[0],\n",
    "                      stats.pearsonr(flat_rsm_r2[roi_idx2,:],flat_rsm_r3[roi_idx2,:])[0]]\n",
    "        NC_target = np.mean(split_half) * 100\n",
    "        \n",
    "        \n",
    "        rsm_corr = np.zeros((6))\n",
    "        \n",
    "        rsm_corr[0] = stats.pearsonr(flat_rsm_r1[roi_idx1,:],\n",
    "                                     flat_rsm_r2[roi_idx2,:])[0]\n",
    "        rsm_corr[1] = stats.pearsonr(flat_rsm_r1[roi_idx1,:],\n",
    "                                     flat_rsm_r3[roi_idx2,:])[0]\n",
    "        rsm_corr[2] = stats.pearsonr(flat_rsm_r2[roi_idx1,:],\n",
    "                                     flat_rsm_r1[roi_idx2,:])[0]\n",
    "        rsm_corr[3] = stats.pearsonr(flat_rsm_r2[roi_idx1,:],\n",
    "                                     flat_rsm_r3[roi_idx2,:])[0]\n",
    "        rsm_corr[4] = stats.pearsonr(flat_rsm_r3[roi_idx1,:],\n",
    "                                     flat_rsm_r1[roi_idx2,:])[0]\n",
    "        rsm_corr[5] = stats.pearsonr(flat_rsm_r3[roi_idx1,:],\n",
    "                                     flat_rsm_r2[roi_idx2,:])[0]\n",
    "        \n",
    "        mega_matrix[roi_idx1,roi_idx2] = np.mean(rsm_corr) * np.sqrt(100/NC_model) * np.sqrt(100/NC_target)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mega_matrix)\n",
    "plt.clim(0,1)\n",
    "plt.colorbar(fraction=0.046, pad=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "x, y = MDS(dissimilarity='precomputed').fit_transform(1-mega_matrix).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import dendrogram, linkage, set_link_color_palette\n",
    "from scipy.spatial.distance import squareform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_mm = np.around(mega_matrix, decimals = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists = squareform(1-sym_mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_matrix = linkage(dists, \"complete\", optimal_ordering=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn = dendrogram(linkage_matrix,\n",
    "                above_threshold_color='#bcbddc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
